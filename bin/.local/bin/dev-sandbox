#!/usr/bin/env bash
set -euo pipefail

# ==============================================================================
# dev-sandbox
#
# Assumptions:
# - Host OS: openSUSE Tumbleweed (or host has zypper installed and configured)
# - Host terminal: kitty (tab-title helper is best-effort; script still works without kitty)
# - Host interactive shell: fish (container sessions start fish)
# - AI CLIs are installed globally inside the container
# - API keys are per-project in .env.ai files (inside each project; not managed by the script)
#
# Notes:
# - First run provisions the rootfs (heavy). Subsequent runs are lightweight.
# - ~/.config is synced on every attach via: rsync -aL --delete
# - Project mapping is basename -> /workspace/<basename>; basename collisions error.
# - Sandbox user policy: if UID conflicts exist, conflicting users may be deleted.
# ==============================================================================

MACHINE="dev-sandbox"
ROOT="/var/lib/machines/${MACHINE}"
NSPAWN_CONF="/etc/systemd/nspawn/${MACHINE}.nspawn"
SENTINEL="${ROOT}/.dev-sandbox/initialized"
LOCK="/var/lock/dev-sandbox.provision.lock"

HOST_USER="$(id -un)"
HOST_UID="$(id -u)"
HOST_GID="$(id -g)"

# Disable systemd terminal tint/title/emoji adjustments (keep host kitty colors intact)
SYSTEMD_TTY_ENV=(
  "SYSTEMD_TINT_BACKGROUND=0"
  "SYSTEMD_ADJUST_TERMINAL_TITLE=0"
  "SYSTEMD_EMOJI=0"
)

# Repo URLs (Tumbleweed)
REPO_OSS="https://cdn.opensuse.org/tumbleweed/repo/oss/"
REPO_NON_OSS="https://cdn.opensuse.org/tumbleweed/repo/non-oss/"
REPO_UPDATE="https://cdn.opensuse.org/update/tumbleweed/"
REPO_SCIENCE_DIR="https://download.opensuse.org/repositories/science/openSUSE_Tumbleweed/"

# Patterns
PATTERNS=( base enhanced_base devel_basis devel_perl )

# Packages (baseline; extend as needed)
CORE_PACKAGES=(
  # Shell
  fish

  # Dev tools (not in devel_basis)
  git
  neovim
  gcc-c++
  cmake
  ninja

  # Modern CLI (not in base)
  rsync
  wget
  ripgrep
  fd

  # Language runtimes
  python3
  python3-pip
  python3-virtualenv
  python313-poetry
  nodejs
  npm
)

OPTIONAL_PACKAGES=(
  # Keep empty or add your stacks.
)

# Globals set during execution
NSPAWN_CREATED=0
PROVISIONED_NOW=0
PROJECT_NAME=""

die() { echo "Error: $*" >&2; exit 1; }
log() { echo "[dev-sandbox] $*" >&2; }

require_cmd() {
  command -v "$1" >/dev/null 2>&1 || die "missing required command: $1"
}

sudo_cmd() {
  sudo env "${SYSTEMD_TTY_ENV[@]}" "$@"
}

sudo_systemd_run() {
  sudo env "${SYSTEMD_TTY_ENV[@]}" systemd-run "$@"
}

usage() {
  cat >&2 <<EOF
Usage:
  dev-sandbox                      # project mode: mount \$PWD -> /workspace/<basename>, attach as host user
  dev-sandbox /path/to/project     # project mode: mount path, attach as host user

Attach modes:
  dev-sandbox -R|--shell-root      # attach as root (no project mount)
  dev-sandbox -D|--shell-dev       # attach as host user (no project mount)

Management:
  dev-sandbox start                # ensure config/rootfs/machine running (idempotent)
  dev-sandbox stop                 # stop machine
  dev-sandbox status               # show status/health summary
  dev-sandbox setup                # force full provisioning (re-run provisioning payload)

Behavior:
  - First run provisions rootfs (heavy); subsequent runs do not touch zypper.
  - Project mapping is basename -> /workspace/<basename>.
  - Basename collisions are errors (existing + requested sources shown).
  - ~/.config is synced on every attach with: rsync -aL --delete
EOF
  exit 1
}

set_kitty_tab_title() {
  local title="$1"
  if [[ -n "${KITTY_WINDOW_ID:-}" ]]; then
    command kitten @ set-tab-title "$title" 2>/dev/null || true
  fi
}

machine_state() {
  sudo_cmd machinectl show "$MACHINE" --property=State --value 2>/dev/null || true
}

machine_is_running() {
  [[ "$(machine_state)" == "running" ]]
}

wait_for_machine_systemd() {
  local i
  for i in {1..30}; do
    if sudo_systemd_run -M "$MACHINE" --pipe --quiet --wait /bin/true >/dev/null 2>&1; then
      return 0
    fi
    sleep 0.2
  done
  return 1
}

ensure_nspawn_config() {
  sudo_cmd install -d -m 0755 /etc/systemd/nspawn

  if ! sudo_cmd test -f "$NSPAWN_CONF"; then
    log "creating nspawn config: $NSPAWN_CONF"
    cat <<EOF | sudo_cmd tee "$NSPAWN_CONF" >/dev/null
[Exec]
Boot=yes
PrivateUsers=no

[Network]
VirtualEthernet=no
EOF
    NSPAWN_CREATED=1
  fi
}

ensure_rootfs_provisioned_if_needed() {
  local force="$1" # 0/1

  local had_sentinel=0
  if sudo_cmd test -f "$SENTINEL" 2>/dev/null; then
    had_sentinel=1
  fi

  local need=0
  if ! sudo_cmd test -d "$ROOT" 2>/dev/null; then
    need=1
  fi
  if ! sudo_cmd test -f "$SENTINEL" 2>/dev/null; then
    need=1
  fi
  if [[ "$force" -eq 1 ]]; then
    need=1
  fi

  if [[ "$need" -eq 0 ]]; then
    return 0
  fi

  provision_rootfs_with_lock "$force"

  if [[ "$had_sentinel" -eq 0 ]] && sudo_cmd test -f "$SENTINEL" 2>/dev/null; then
    PROVISIONED_NOW=1
  fi
}

provision_rootfs_with_lock() {
  local force="$1" # 0/1

  sudo_cmd install -d -m 0755 "$(dirname "$LOCK")"
  sudo_cmd touch "$LOCK"

  log "provisioning rootfs (locked): $ROOT"
  sudo_cmd flock -x "$LOCK" bash -lc "
    set -euo pipefail

    ROOT='$ROOT'
    SENTINEL='$SENTINEL'
    FORCE='$force'

    REPO_OSS='$REPO_OSS'
    REPO_NON_OSS='$REPO_NON_OSS'
    REPO_UPDATE='$REPO_UPDATE'
    REPO_SCIENCE_DIR='$REPO_SCIENCE_DIR'

    if [[ \"\$FORCE\" -ne 1 ]] && [[ -f \"\$SENTINEL\" ]]; then
      exit 0
    fi

    trap 'cat >&2 <<MSG
[dev-sandbox] provisioning failed; sentinel not written; next run will retry.
[dev-sandbox] after fixing network/repos, you can force reprovision with: dev-sandbox setup
[dev-sandbox] full reset (DESTROYS ROOTFS): sudo rm -rf /var/lib/machines/dev-sandbox
MSG
      exit 1' ERR

    install -d -m 0755 \"\$ROOT\"
    rpm --root \"\$ROOT\" --initdb || true

    # Add repos inside the rootfs (best-effort if already present)
    zypper -n --root \"\$ROOT\" ar -f \"\$REPO_OSS\" repo-oss >/dev/null 2>&1 || true
    zypper -n --root \"\$ROOT\" ar -f \"\$REPO_NON_OSS\" repo-non-oss >/dev/null 2>&1 || true
    zypper -n --root \"\$ROOT\" ar -f \"\$REPO_UPDATE\" repo-update >/dev/null 2>&1 || true
    zypper -n --root \"\$ROOT\" ar -f \"\$REPO_SCIENCE_DIR\" science >/dev/null 2>&1 || true

    zypper -n --gpg-auto-import-keys --root \"\$ROOT\" refresh

    # Patterns
    zypper -n --root \"\$ROOT\" install -t pattern ${PATTERNS[*]}

    # Core packages
    zypper -n --root \"\$ROOT\" install --no-recommends ${CORE_PACKAGES[*]}

    # Optional packages (only if non-empty)
    if [[ -n \"${OPTIONAL_PACKAGES[*]:-}\" ]]; then
      zypper -n --root \"\$ROOT\" install --no-recommends ${OPTIONAL_PACKAGES[*]}
    fi

    zypper -n --root \"\$ROOT\" clean -a || true

    systemd-machine-id-setup --root=\"\$ROOT\"

    install -d -m 0755 \"\$ROOT/workspace\" \"\$ROOT/.dev-sandbox\"

    # Sentinel written only at the end on success
    date -Iseconds > \"\$SENTINEL\"
  "
}

ensure_machine_running() {
  local state
  state="$(machine_state)"

  if [[ "$state" != "running" ]]; then
    log "starting machine: $MACHINE"
    sudo_cmd machinectl start "$MACHINE"
  elif [[ "$NSPAWN_CREATED" -eq 1 ]]; then
    log "nspawn config created; restarting machine to apply config"
    sudo_cmd machinectl poweroff "$MACHINE" || sudo_cmd machinectl terminate "$MACHINE" || true
    sudo_cmd machinectl start "$MACHINE"
  fi

  if ! wait_for_machine_systemd; then
    die "machine started but container systemd is not responding (systemd-run -M failed)"
  fi

  if [[ "$PROVISIONED_NOW" -eq 1 ]]; then
    sudo_cmd machinectl enable "$MACHINE" >/dev/null 2>&1 || true
  fi
}

ensure_host_user_in_container() {
  log "ensuring host user exists in container: $HOST_USER ($HOST_UID:$HOST_GID)"

  sudo_systemd_run -M "$MACHINE" --pipe --quiet --wait \
    -E "HOST_USER=$HOST_USER" \
    -E "HOST_UID=$HOST_UID" \
    -E "HOST_GID=$HOST_GID" \
    /bin/bash -c '
      set -euo pipefail

      delete_user_best_effort() {
        local name="$1"
        local uid="$2"
        local i

        # Best-effort: kill processes + retry userdel a few times to avoid “user logged in” races.
        for i in 1 2 3 4 5; do
          pkill -KILL -u "$uid" 2>/dev/null || true
          sleep 0.1
          userdel -r "$name" 2>/dev/null && return 0
          userdel "$name" 2>/dev/null && return 0
          sleep 0.2
        done
        return 0
      }

      delete_group_best_effort() {
        local name="$1"
        local i

        for i in 1 2 3 4 5; do
          groupdel "$name" 2>/dev/null && return 0
          sleep 0.1
        done
        return 0
      }

      # Ensure group/user are exactly HOST_USER@HOST_UID:HOST_GID (simplest sandbox policy: delete conflicts)
      existing_user_by_uid="$(getent passwd "$HOST_UID" 2>/dev/null | cut -d: -f1 || true)"
      if [[ -n "$existing_user_by_uid" && "$existing_user_by_uid" != "$HOST_USER" ]]; then
        delete_user_best_effort "$existing_user_by_uid" "$HOST_UID"
      fi

      if getent passwd "$HOST_USER" >/dev/null 2>&1; then
        current_uid="$(id -u "$HOST_USER")"
        if [[ "$current_uid" != "$HOST_UID" ]]; then
          delete_user_best_effort "$HOST_USER" "$current_uid"
        fi
      fi

      existing_group_by_gid="$(getent group "$HOST_GID" 2>/dev/null | cut -d: -f1 || true)"
      if [[ -n "$existing_group_by_gid" && "$existing_group_by_gid" != "$HOST_USER" ]]; then
        delete_group_best_effort "$existing_group_by_gid"
      fi

      if getent group "$HOST_USER" >/dev/null 2>&1; then
        current_gid="$(getent group "$HOST_USER" | cut -d: -f3)"
        if [[ "$current_gid" != "$HOST_GID" ]]; then
          delete_group_best_effort "$HOST_USER"
        fi
      fi

      # Now create (useradd -U creates a group with the same user name)
      if ! getent passwd "$HOST_USER" >/dev/null 2>&1; then
        useradd -m -u "$HOST_UID" -U -s /usr/bin/fish "$HOST_USER"
      fi

      # Force group gid and user primary group to match host
      groupmod -g "$HOST_GID" "$HOST_USER"
      usermod -g "$HOST_USER" -s /usr/bin/fish -d "/home/$HOST_USER" "$HOST_USER" || true

      mkdir -p "/home/$HOST_USER" /workspace
      chown -R "$HOST_UID:$HOST_GID" "/home/$HOST_USER"
    '
}

sync_host_config_every_attach() {
  mkdir -p "$HOME/.config"
  sudo_cmd install -d -m 0755 "$ROOT/home/$HOST_USER/.config"
  log "syncing host ~/.config -> container (~/.config) with rsync -aL --delete"
  sudo_cmd rsync -aL --delete "$HOME/.config/" "$ROOT/home/$HOST_USER/.config/"
  sudo_cmd chown -R "$HOST_UID:$HOST_GID" "$ROOT/home/$HOST_USER/.config"
}

bind_project_with_collision_check() {
  local project_path="$1"
  project_path="$(readlink -f "$project_path")"
  PROJECT_NAME="$(basename "$project_path")"
  local target="/workspace/$PROJECT_NAME"

  local existing_source
  existing_source="$(
    sudo_systemd_run -M "$MACHINE" --pipe --quiet --wait \
      /usr/bin/findmnt -n -o SOURCE --mountpoint "$target" 2>/dev/null | tr -d "\n" || true
  )"

  if [[ -n "$existing_source" ]]; then
    if [[ "$existing_source" == "$project_path" ]]; then
      return 0
    fi
    die "basename collision for $target
  existing source: $existing_source
  requested source: $project_path"
  fi

  log "binding project: $project_path -> $target"
  sudo_cmd machinectl bind "$MACHINE" "$project_path" "$target" --mkdir
}

attach_root() {
  set_kitty_tab_title "$MACHINE"
  sudo_systemd_run -M "$MACHINE" --pty --quiet --wait \
    -E "DEV_SANDBOX=$MACHINE" \
    /usr/bin/fish
}

attach_host_user_shell() {
  set_kitty_tab_title "$MACHINE"
  sudo_systemd_run -M "$MACHINE" --pty --quiet --wait --uid="$HOST_UID" \
    -E "DEV_SANDBOX=$MACHINE" \
    /usr/bin/fish
}

attach_project() {
  set_kitty_tab_title "$MACHINE:$PROJECT_NAME"
  sudo_systemd_run -M "$MACHINE" --pty --quiet --wait --uid="$HOST_UID" \
    -E "DEV_SANDBOX=$MACHINE" \
    -E "DEV_SANDBOX_PROJECT=$PROJECT_NAME" \
    /usr/bin/fish -lc "cd /workspace/$PROJECT_NAME; exec fish"
}

cmd_start() {
  ensure_nspawn_config
  ensure_rootfs_provisioned_if_needed 0
  ensure_machine_running
  ensure_host_user_in_container
}

cmd_stop() {
  if machine_is_running; then
    log "stopping machine: $MACHINE"
    sudo_cmd machinectl poweroff "$MACHINE" || sudo_cmd machinectl terminate "$MACHINE" || true
  else
    log "machine not running: $MACHINE"
  fi
}

cmd_setup() {
  ensure_nspawn_config
  if machine_is_running; then
    log "stopping machine for setup: $MACHINE"
    sudo_cmd machinectl poweroff "$MACHINE" || sudo_cmd machinectl terminate "$MACHINE" || true
  fi
  ensure_rootfs_provisioned_if_needed 1
  ensure_machine_running
  ensure_host_user_in_container
}

cmd_status() {
  local rootfs="absent"
  local sentinel="absent"
  local conf="absent"
  local state="(unknown)"
  local user_status="(unknown)"

  if sudo_cmd test -d "$ROOT" 2>/dev/null; then rootfs="present"; fi
  if sudo_cmd test -f "$SENTINEL" 2>/dev/null; then sentinel="present"; fi
  if sudo_cmd test -f "$NSPAWN_CONF" 2>/dev/null; then conf="present"; fi

  state="$(machine_state)"
  if [[ -z "$state" ]]; then state="not running"; fi

  if [[ "$state" == "running" ]]; then
    if sudo_systemd_run -M "$MACHINE" --pipe --quiet --wait /usr/bin/id -u "$HOST_USER" >/dev/null 2>&1; then
      user_status="present ($HOST_USER)"
    else
      user_status="missing ($HOST_USER)"
    fi
  fi

  cat <<EOF
Machine:        $MACHINE
Rootfs:         $rootfs ($ROOT)
Sentinel:       $sentinel ($SENTINEL)
Nspawn config:  $conf ($NSPAWN_CONF)
State:          $state
Host user:      $user_status
EOF
}

main() {
  require_cmd sudo
  require_cmd machinectl
  require_cmd systemd-run
  require_cmd zypper
  require_cmd rpm
  require_cmd rsync
  require_cmd flock
  require_cmd readlink

  sudo -v

  if [[ $# -eq 0 ]]; then
    local project_path="$PWD"
    cmd_start
    sync_host_config_every_attach
    bind_project_with_collision_check "$project_path"
    attach_project
    return 0
  fi

  case "$1" in
    -h|--help) usage ;;

    start)  shift; [[ $# -eq 0 ]] || usage; cmd_start ;;
    stop)   shift; [[ $# -eq 0 ]] || usage; cmd_stop ;;
    status) shift; [[ $# -eq 0 ]] || usage; cmd_status ;;
    setup)  shift; [[ $# -eq 0 ]] || usage; cmd_setup ;;

    -R|--shell-root)
      shift
      [[ $# -eq 0 ]] || usage
      cmd_start
      sync_host_config_every_attach
      attach_root
      ;;

    -D|--shell-dev)
      shift
      [[ $# -eq 0 ]] || usage
      cmd_start
      sync_host_config_every_attach
      attach_host_user_shell
      ;;

    -*)
      die "unknown option: $1"
      ;;

    *)
      local project_path="$1"
      shift
      [[ $# -eq 0 ]] || die "multiple project paths provided"
      [[ -d "$project_path" ]] || die "project directory does not exist: $project_path"

      cmd_start
      sync_host_config_every_attach
      bind_project_with_collision_check "$project_path"
      attach_project
      ;;
  esac
}

main "$@"
